{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "TOPIC_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", TOPIC_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('new_data.csv') \n",
    "new_mdb = data[[ \"CMRSET.ET\", \"RAD\", \"LST\", \"EVI\", \"NDVI\", \"SM\", \"LAI\", \"LAT\", \"LON\", \"Field.ET\"]]\n",
    "new_mdb = new_mdb.sample(frac=1) # Shuffle the data\n",
    "\n",
    "X =  new_mdb.iloc[:, :-1].values # Variables used in the model to determine the predictor\n",
    "y = new_mdb.iloc[:, -1].values # Predictor: 'residual'\n",
    "LENGTH = len(new_mdb)\n",
    "df_leave_one_out = pd.DataFrame(columns=['ML Algorithm', 'MSE', 'RMSE', 'R^2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Cross Validation on Predicted.ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ML Algorithm     MSE   RMSE   R^2\n",
       "0  Decision Tree  109.46  10.46  0.72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=5, random_state=42) \n",
    "\n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    tree.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = tree.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'Decision Tree', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Predicted ET directly GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ML Algorithm     MSE   RMSE   R^2\n",
       "0  Decision Tree  109.46  10.46  0.72\n",
       "1  Random Forest   63.53   7.97  0.84"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestRegressor(n_estimators=300, min_samples_split = 7, random_state=42) # Similar results, less trees\n",
    "\n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    rnd_clf.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = rnd_clf.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'Random Forest', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ML Algorithm     MSE   RMSE   R^2\n",
       "0      Decision Tree  109.46  10.46  0.72\n",
       "1      Random Forest   63.53   7.97  0.84\n",
       "2  Gradient Boosting   60.50   7.78  0.84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up Gradient Boosting parameters\n",
    "gb_clf = GradientBoostingRegressor(max_depth=5,\n",
    "                                   min_samples_split=7,\n",
    "                                   n_estimators=200,\n",
    "                                   learning_rate=0.1,\n",
    "                                   random_state=42)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    gb_clf.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = gb_clf.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'Gradient Boosting', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>80.79</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ML Algorithm     MSE   RMSE   R^2\n",
       "0      Decision Tree  109.46  10.46  0.72\n",
       "1      Random Forest   63.53   7.97  0.84\n",
       "2  Gradient Boosting   60.50   7.78  0.84\n",
       "3       Ada Boosting   80.79   8.99  0.79"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostRegressor(learning_rate = 0.1, n_estimators=200, random_state=42)\n",
    "\n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    ada_clf.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = ada_clf.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'Ada Boosting', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>80.79</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>64.84</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ML Algorithm     MSE   RMSE   R^2\n",
       "0      Decision Tree  109.46  10.46  0.72\n",
       "1      Random Forest   63.53   7.97  0.84\n",
       "2  Gradient Boosting   60.50   7.78  0.84\n",
       "3       Ada Boosting   80.79   8.99  0.79\n",
       "4  Bagging Regressor   64.84   8.05  0.83"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_reg = BaggingRegressor(n_estimators=300, random_state=42)\n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    bag_reg.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = bag_reg.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'Bagging Regressor', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>80.79</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>64.84</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM Regressor</td>\n",
       "      <td>227.35</td>\n",
       "      <td>15.08</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ML Algorithm     MSE   RMSE   R^2\n",
       "0      Decision Tree  109.46  10.46  0.72\n",
       "1      Random Forest   63.53   7.97  0.84\n",
       "2  Gradient Boosting   60.50   7.78  0.84\n",
       "3       Ada Boosting   80.79   8.99  0.79\n",
       "4  Bagging Regressor   64.84   8.05  0.83\n",
       "5      SVM Regressor  227.35  15.08  0.41"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.5, kernel = \"sigmoid\"))\n",
    "\n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    svm_regr.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = svm_regr.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'SVM Regressor', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>80.79</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>64.84</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM Regressor</td>\n",
       "      <td>227.35</td>\n",
       "      <td>15.08</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>126.43</td>\n",
       "      <td>11.24</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ML Algorithm     MSE   RMSE   R^2\n",
       "0      Decision Tree  109.46  10.46  0.72\n",
       "1      Random Forest   63.53   7.97  0.84\n",
       "2  Gradient Boosting   60.50   7.78  0.84\n",
       "3       Ada Boosting   80.79   8.99  0.79\n",
       "4  Bagging Regressor   64.84   8.05  0.83\n",
       "5      SVM Regressor  227.35  15.08  0.41\n",
       "6           Stacking  126.43  11.24  0.67"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "     ('gb', GradientBoostingRegressor(max_depth=5,\n",
    "                                   min_samples_split = 7,\n",
    "                                   n_estimators=300,\n",
    "                                   learning_rate=0.1,\n",
    "                                   random_state=42)),\n",
    "     ('rf', RandomForestRegressor(n_estimators=300, min_samples_split = 7, random_state=42)),\n",
    "     ('bg', BaggingRegressor(n_estimators=300, random_state=42))\n",
    "\n",
    "]\n",
    "\n",
    "stack_reg = StackingRegressor(\n",
    "     estimators=estimators\n",
    " )\n",
    "\n",
    "\n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    stack_reg.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = stack_reg.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'Stacking', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>80.79</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>64.84</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM Regressor</td>\n",
       "      <td>227.35</td>\n",
       "      <td>15.08</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>126.43</td>\n",
       "      <td>11.24</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>147.60</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ML Algorithm     MSE   RMSE   R^2\n",
       "0      Decision Tree  109.46  10.46  0.72\n",
       "1      Random Forest   63.53   7.97  0.84\n",
       "2  Gradient Boosting   60.50   7.78  0.84\n",
       "3       Ada Boosting   80.79   8.99  0.79\n",
       "4  Bagging Regressor   64.84   8.05  0.83\n",
       "5      SVM Regressor  227.35  15.08  0.41\n",
       "6           Stacking  126.43  11.24  0.67\n",
       "7  Linear Regression  147.60  12.15  0.62"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    lin_reg.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = lin_reg.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'Linear Regression', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority voting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>80.79</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>64.84</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM Regressor</td>\n",
       "      <td>227.35</td>\n",
       "      <td>15.08</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>126.43</td>\n",
       "      <td>11.24</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>147.60</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Majority Voting Regressor</td>\n",
       "      <td>64.04</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ML Algorithm     MSE   RMSE   R^2\n",
       "0              Decision Tree  109.46  10.46  0.72\n",
       "1              Random Forest   63.53   7.97  0.84\n",
       "2          Gradient Boosting   60.50   7.78  0.84\n",
       "3               Ada Boosting   80.79   8.99  0.79\n",
       "4          Bagging Regressor   64.84   8.05  0.83\n",
       "5              SVM Regressor  227.35  15.08  0.41\n",
       "6                   Stacking  126.43  11.24  0.67\n",
       "7          Linear Regression  147.60  12.15  0.62\n",
       "8  Majority Voting Regressor   64.04   8.00  0.83"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "rnd_clf = RandomForestRegressor(n_estimators=300, min_samples_split = 7, random_state=42)\n",
    "gb_clf = GradientBoostingRegressor(max_depth=5,\n",
    "                                   min_samples_split = 7,\n",
    "                                   n_estimators=300,\n",
    "                                   learning_rate=0.1,\n",
    "                                   random_state=42)\n",
    "bag_reg = BaggingRegressor(n_estimators=300, random_state=42)\n",
    "# tree = DecisionTreeRegressor(max_depth=5, random_state=42) \n",
    "# lin_reg = LinearRegression()\n",
    "\n",
    "er = VotingRegressor([('rf', rnd_clf), ('gb', gb_clf), ('bg', bag_reg)]) # ('tree', tree), ('lin_reg', lin_reg)\n",
    "\n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    er.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = er.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'Majority Voting Regressor', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>80.79</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>64.84</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM Regressor</td>\n",
       "      <td>227.35</td>\n",
       "      <td>15.08</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>126.43</td>\n",
       "      <td>11.24</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>147.60</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Majority Voting Regressor</td>\n",
       "      <td>64.04</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>113.42</td>\n",
       "      <td>10.65</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ML Algorithm     MSE   RMSE   R^2\n",
       "0              Decision Tree  109.46  10.46  0.72\n",
       "1              Random Forest   63.53   7.97  0.84\n",
       "2          Gradient Boosting   60.50   7.78  0.84\n",
       "3               Ada Boosting   80.79   8.99  0.79\n",
       "4          Bagging Regressor   64.84   8.05  0.83\n",
       "5              SVM Regressor  227.35  15.08  0.41\n",
       "6                   Stacking  126.43  11.24  0.67\n",
       "7          Linear Regression  147.60  12.15  0.62\n",
       "8  Majority Voting Regressor   64.04   8.00  0.83\n",
       "9              KNN Regressor  113.42  10.65  0.71"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_reg = KNeighborsRegressor(n_neighbors = 5) \n",
    "# Set up GMM parameters\n",
    "k = 2\n",
    "gmm = GaussianMixture(n_components=k)\n",
    "\n",
    "# Set up K-Fold cross validation\n",
    "cv = KFold(n_splits=len(X), shuffle=False)\n",
    "\n",
    "# Set up an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['predicted', 'actual'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Iterate over the cross validation splits\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Fit the GMM model to the training data and make predictions for the test data\n",
    "    gmm.fit(X_train)\n",
    "    test_cluster = gmm.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get the training data corresponding to the closest cluster\n",
    "    cluster_X = X_train[gmm.predict(X_train) == test_cluster]\n",
    "    cluster_y = y_train[gmm.predict(X_train) == test_cluster]\n",
    "    \n",
    "    # Fit the Gradient Boosting model to the training data for the selected cluster\n",
    "    knn_reg.fit(cluster_X, cluster_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = knn_reg.predict(X_test.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store the predicted and actual values in the results DataFrame\n",
    "    results = results.append({'predicted': y_pred, 'actual': y_test[0]}, ignore_index=True)\n",
    "\n",
    "# Calculate the R-squared score for the predictions\n",
    "r2 = r2_score(results['actual'], results['predicted'])\n",
    "mse = mean_squared_error(results['actual'], results['predicted'])\n",
    "d = [f'KNN Regressor', round(mse, 2),  round((mse)**(1/2.0), 2), round(r2_score(results['actual'], results['predicted']), 2) ] # round(scores_r2.mean(), 2)\n",
    "df_leave_one_out.loc[len(df_leave_one_out)] = d\n",
    "\n",
    "df_leave_one_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>60.50</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Majority Voting Regressor</td>\n",
       "      <td>64.04</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>64.84</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>80.79</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>109.46</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>113.42</td>\n",
       "      <td>10.65</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>126.43</td>\n",
       "      <td>11.24</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>147.60</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM Regressor</td>\n",
       "      <td>227.35</td>\n",
       "      <td>15.08</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ML Algorithm     MSE   RMSE   R^2\n",
       "2          Gradient Boosting   60.50   7.78  0.84\n",
       "1              Random Forest   63.53   7.97  0.84\n",
       "8  Majority Voting Regressor   64.04   8.00  0.83\n",
       "4          Bagging Regressor   64.84   8.05  0.83\n",
       "3               Ada Boosting   80.79   8.99  0.79\n",
       "0              Decision Tree  109.46  10.46  0.72\n",
       "9              KNN Regressor  113.42  10.65  0.71\n",
       "6                   Stacking  126.43  11.24  0.67\n",
       "7          Linear Regression  147.60  12.15  0.62\n",
       "5              SVM Regressor  227.35  15.08  0.41"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_df = df_leave_one_out.sort_values(by = 'MSE')\n",
    "rslt_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9470b8784b959759c7c699b367576c0be7b48eef9ff58c8b0d64956fc07e03c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
